{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a357d2b-0d47-47ca-ba64-13e529337eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š LEVEL 5: BUSINESS INTELLIGENCE & CLOUD DEPLOYMENT\n",
      "======================================================================\n",
      "Analysis Date: 2026-02-14 10:29\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ STEP 5.0: Loading data and models from Level 4...\n",
      "âœ… Loaded data: 15,000 policies\n",
      "âœ… Loaded XGBoost classification model\n",
      "âœ… Loaded XGBoost regression model\n",
      "âœ… Loaded 12 features\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š STEP 5A.1: POWERBI DATA PREPARATION\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ Creating PowerBI dataset...\n",
      "   Original columns: 15\n",
      "âœ… Enhanced dataset: 23 columns\n",
      "\n",
      "ğŸ”§ Recreating engineered features for predictions...\n",
      "âœ… All required features recreated\n",
      "âœ… All 12 features available\n",
      "âœ… Model predictions added\n",
      "\n",
      "ğŸ“Š Creating summary tables...\n",
      "âœ… State summary: 56 states\n",
      "âœ… Risk summary: 5 categories\n",
      "\n",
      "ğŸ’¾ Saving PowerBI files...\n",
      "âœ… Main data: outputs/powerbi/climate_risk_data.csv\n",
      "âœ… State summary: outputs/powerbi/state_summary.csv\n",
      "âœ… Risk summary: outputs/powerbi/risk_summary.csv\n",
      "âœ… Data dictionary: outputs/powerbi/DATA_DICTIONARY.txt\n",
      "\n",
      "======================================================================\n",
      "âœ… POWERBI DATA PREPARATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Dataset Summary:\n",
      "   Records:     15,000\n",
      "   Columns:     23\n",
      "   States:      56\n",
      "   Total Value: $4.83B\n",
      "\n",
      "ğŸ“‚ Files ready for PowerBI:\n",
      "   1. climate_risk_data.csv     (15,000 rows)\n",
      "   2. state_summary.csv         (56 states)\n",
      "   3. risk_summary.csv          (5 categories)\n",
      "   4. DATA_DICTIONARY.txt       (column guide)\n",
      "\n",
      "ğŸ¯ Next Steps:\n",
      "   1. Open PowerBI Desktop\n",
      "   2. Import climate_risk_data.csv\n",
      "   3. Follow dashboard creation guide\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LEVEL 5: BUSINESS INTELLIGENCE & CLOUD DEPLOYMENT\n",
    "# Climate Risk Insurance Project\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š LEVEL 5: BUSINESS INTELLIGENCE & CLOUD DEPLOYMENT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEP 5.0: LOAD DATA & MODELS FROM LEVEL 4\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ“‚ STEP 5.0: Loading data and models from Level 4...\")\n",
    "\n",
    "# Load processed data\n",
    "df_model = pd.read_csv('data/processed/final_model_data.csv')\n",
    "print(f\"âœ… Loaded data: {len(df_model):,} policies\")\n",
    "\n",
    "# Load trained models\n",
    "with open('outputs/models/xgb_classification_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "print(\"âœ… Loaded XGBoost classification model\")\n",
    "\n",
    "with open('outputs/models/xgb_regression_model.pkl', 'rb') as f:\n",
    "    xgb_reg = pickle.load(f)\n",
    "print(\"âœ… Loaded XGBoost regression model\")\n",
    "\n",
    "# Load feature list\n",
    "with open('outputs/models/feature_list.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    # Extract feature names from the file\n",
    "    feature_lines = [line.strip() for line in content.split('\\n') if line.strip() and line[0].isdigit()]\n",
    "    model_features = [line.split('. ')[1] for line in feature_lines]\n",
    "\n",
    "print(f\"âœ… Loaded {len(model_features)} features\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEP 5A.1: PREPARE DATA FOR POWERBI\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š STEP 5A.1: POWERBI DATA PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create PowerBI directory\n",
    "os.makedirs('outputs/powerbi', exist_ok=True)\n",
    "\n",
    "# Select relevant columns for PowerBI\n",
    "powerbi_columns = [\n",
    "    'policy_id', 'state', 'county', 'latitude', 'longitude',\n",
    "    'property_value', 'property_age', 'building_type',\n",
    "    'RISK_SCORE', 'current_annual_premium', 'coverage_amount', \n",
    "    'deductible', 'policy_start_year',\n",
    "    'num_claims_5yr', 'total_claim_amount_5yr'\n",
    "]\n",
    "\n",
    "# Check which columns exist\n",
    "available_cols = [col for col in powerbi_columns if col in df_model.columns]\n",
    "powerbi_data = df_model[available_cols].copy()\n",
    "\n",
    "print(f\"\\nğŸ“‹ Creating PowerBI dataset...\")\n",
    "print(f\"   Original columns: {len(available_cols)}\")\n",
    "\n",
    "# Add calculated columns for PowerBI\n",
    "powerbi_data['Year'] = 2024\n",
    "powerbi_data['policy_age'] = 2024 - powerbi_data['policy_start_year']\n",
    "\n",
    "# Risk categories\n",
    "powerbi_data['Risk_Category'] = pd.cut(\n",
    "    powerbi_data['RISK_SCORE'],\n",
    "    bins=[0, 20, 40, 60, 80, 100],\n",
    "    labels=['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "# Premium categories\n",
    "powerbi_data['Premium_Category'] = pd.cut(\n",
    "    powerbi_data['current_annual_premium'],\n",
    "    bins=[0, 1500, 2500, 3500, 5000, 10000],\n",
    "    labels=['< $1.5K', '$1.5K-$2.5K', '$2.5K-$3.5K', '$3.5K-$5K', '> $5K']\n",
    ")\n",
    "\n",
    "# Claim status\n",
    "powerbi_data['has_claim'] = (powerbi_data['num_claims_5yr'] > 0).astype(int)\n",
    "powerbi_data['Claim_Status'] = powerbi_data['has_claim'].map({0: 'No Claim', 1: 'Has Claim'})\n",
    "\n",
    "# Coverage ratio\n",
    "powerbi_data['coverage_ratio'] = powerbi_data['coverage_amount'] / powerbi_data['property_value']\n",
    "\n",
    "# Loss ratio\n",
    "powerbi_data['Loss_Ratio'] = (\n",
    "    powerbi_data['total_claim_amount_5yr'] / \n",
    "    (powerbi_data['current_annual_premium'] * 5)\n",
    ").fillna(0).clip(0, 5)\n",
    "\n",
    "print(f\"âœ… Enhanced dataset: {powerbi_data.shape[1]} columns\")\n",
    "\n",
    "# Prepare features for model predictions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Recreate Missing Features for Model Predictions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ”§ Recreating engineered features for predictions...\")\n",
    "\n",
    "# Create composite_risk if missing\n",
    "if 'composite_risk' not in df_model.columns:\n",
    "    df_model['composite_risk'] = df_model['RISK_SCORE'].copy()\n",
    "    if 'CFLD_RISKS' in df_model.columns:\n",
    "        df_model['composite_risk'] += df_model['CFLD_RISKS'].replace(-9999, 0) * 0.3\n",
    "    if 'WFIR_RISKS' in df_model.columns:\n",
    "        df_model['composite_risk'] += df_model['WFIR_RISKS'].replace(-9999, 0) * 0.3\n",
    "\n",
    "# Create risk indicators if missing\n",
    "if 'is_high_risk' not in df_model.columns:\n",
    "    df_model['is_high_risk'] = (df_model['RISK_SCORE'] > 60).astype(int)\n",
    "\n",
    "if 'is_very_high_risk' not in df_model.columns:\n",
    "    df_model['is_very_high_risk'] = (df_model['RISK_SCORE'] > 80).astype(int)\n",
    "\n",
    "# Create property features if missing\n",
    "if 'age_risk_interaction' not in df_model.columns:\n",
    "    df_model['age_risk_interaction'] = df_model['property_age'] * df_model['RISK_SCORE']\n",
    "\n",
    "if 'is_single_family' not in df_model.columns:\n",
    "    df_model['is_single_family'] = (df_model['building_type'] == 'Single_Family').astype(int)\n",
    "\n",
    "if 'is_commercial' not in df_model.columns:\n",
    "    df_model['is_commercial'] = (df_model['building_type'] == 'Commercial').astype(int)\n",
    "\n",
    "# Create policy features if missing\n",
    "if 'coverage_ratio' not in df_model.columns:\n",
    "    df_model['coverage_ratio'] = df_model['coverage_amount'] / df_model['property_value']\n",
    "\n",
    "if 'policy_age' not in df_model.columns:\n",
    "    df_model['policy_age'] = 2024 - df_model['policy_start_year']\n",
    "\n",
    "if 'has_high_deductible' not in df_model.columns:\n",
    "    df_model['has_high_deductible'] = (df_model['deductible'] >= 5000).astype(int)\n",
    "\n",
    "# Create geographic features if missing\n",
    "if 'is_high_risk_state' not in df_model.columns:\n",
    "    high_risk_states = ['CA', 'FL', 'TX', 'LA', 'NY', 'NJ']\n",
    "    df_model['is_high_risk_state'] = df_model['state'].isin(high_risk_states).astype(int)\n",
    "\n",
    "# Create construction features if missing\n",
    "if 'construction_type' in df_model.columns:\n",
    "    if 'is_wood_construction' not in df_model.columns:\n",
    "        df_model['is_wood_construction'] = (df_model['construction_type'] == 'Wood').astype(int)\n",
    "    if 'is_fire_resistant' not in df_model.columns:\n",
    "        df_model['is_fire_resistant'] = df_model['construction_type'].isin(['Steel', 'Concrete']).astype(int)\n",
    "\n",
    "print(\"âœ… All required features recreated\")\n",
    "\n",
    "# Verify all features exist\n",
    "missing_features = [f for f in model_features if f not in df_model.columns]\n",
    "if missing_features:\n",
    "    print(f\"âš ï¸  Still missing: {missing_features}\")\n",
    "    # Use only available features\n",
    "    available_features = [f for f in model_features if f in df_model.columns]\n",
    "    print(f\"âœ… Using {len(available_features)} available features\")\n",
    "    X_features = df_model[available_features].copy()\n",
    "else:\n",
    "    print(f\"âœ… All {len(model_features)} features available\")\n",
    "    X_features = df_model[model_features].copy()\n",
    "print(\"âœ… Model predictions added\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Create Summary Tables\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ“Š Creating summary tables...\")\n",
    "\n",
    "# State summary\n",
    "state_summary = powerbi_data.groupby('state').agg({\n",
    "    'policy_id': 'count',\n",
    "    'property_value': 'sum',\n",
    "    'current_annual_premium': ['sum', 'mean'],\n",
    "    'RISK_SCORE': 'mean',\n",
    "    'num_claims_5yr': 'sum',\n",
    "    'total_claim_amount_5yr': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "state_summary.columns = [\n",
    "    'Total_Policies', 'Total_Property_Value', 'Total_Premium', \n",
    "    'Avg_Premium', 'Avg_Risk_Score', 'Total_Claims', 'Total_Claim_Amount'\n",
    "]\n",
    "state_summary = state_summary.reset_index()\n",
    "state_summary['Claim_Rate'] = (\n",
    "    state_summary['Total_Claims'] / (state_summary['Total_Policies'] * 5) * 100\n",
    ").round(1)\n",
    "state_summary['Loss_Ratio'] = (\n",
    "    state_summary['Total_Claim_Amount'] / (state_summary['Total_Premium'] * 5) * 100\n",
    ").round(1)\n",
    "\n",
    "print(f\"âœ… State summary: {len(state_summary)} states\")\n",
    "\n",
    "# Risk category summary\n",
    "risk_summary = powerbi_data.groupby('Risk_Category').agg({\n",
    "    'policy_id': 'count',\n",
    "    'current_annual_premium': 'mean',\n",
    "    'num_claims_5yr': 'sum',\n",
    "    'total_claim_amount_5yr': 'sum'\n",
    "}).round(2)\n",
    "risk_summary.columns = ['Policies', 'Avg_Premium', 'Total_Claims', 'Claim_Amount']\n",
    "risk_summary = risk_summary.reset_index()\n",
    "risk_summary['Claim_Rate'] = (\n",
    "    risk_summary['Total_Claims'] / (risk_summary['Policies'] * 5) * 100\n",
    ").round(1)\n",
    "\n",
    "print(f\"âœ… Risk summary: {len(risk_summary)} categories\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Save Files\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving PowerBI files...\")\n",
    "\n",
    "powerbi_data.to_csv('outputs/powerbi/climate_risk_data.csv', index=False)\n",
    "print(\"âœ… Main data: outputs/powerbi/climate_risk_data.csv\")\n",
    "\n",
    "state_summary.to_csv('outputs/powerbi/state_summary.csv', index=False)\n",
    "print(\"âœ… State summary: outputs/powerbi/state_summary.csv\")\n",
    "\n",
    "risk_summary.to_csv('outputs/powerbi/risk_summary.csv', index=False)\n",
    "print(\"âœ… Risk summary: outputs/powerbi/risk_summary.csv\")\n",
    "\n",
    "# Data dictionary\n",
    "data_dictionary = f\"\"\"\n",
    "CLIMATE RISK INSURANCE - POWERBI DATA DICTIONARY\n",
    "================================================\n",
    "\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "MAIN DATASET: climate_risk_data.csv ({len(powerbi_data):,} records)\n",
    "-----------------------------------------------------------\n",
    "\n",
    "IDENTIFIERS:\n",
    "- policy_id: Unique policy identifier\n",
    "\n",
    "LOCATION:\n",
    "- state: US state (2-letter code)\n",
    "- county: County name\n",
    "- latitude: Geographic latitude\n",
    "- longitude: Geographic longitude\n",
    "\n",
    "PROPERTY:\n",
    "- property_value: Property value ($)\n",
    "- property_age: Age in years\n",
    "- building_type: Single_Family/Multi_Family/Commercial\n",
    "\n",
    "RISK:\n",
    "- RISK_SCORE: FEMA risk (0-100, higher = riskier)\n",
    "- Risk_Category: Very Low/Low/Moderate/High/Very High\n",
    "\n",
    "FINANCIAL:\n",
    "- current_annual_premium: Current premium ($)\n",
    "- coverage_amount: Coverage ($)\n",
    "- deductible: Deductible amount ($)\n",
    "- Premium_Category: Premium bracket\n",
    "- coverage_ratio: Coverage/Property Value\n",
    "\n",
    "CLAIMS:\n",
    "- num_claims_5yr: Claims in past 5 years\n",
    "- total_claim_amount_5yr: Total claims ($)\n",
    "- has_claim: 0 or 1\n",
    "- Claim_Status: \"No Claim\" or \"Has Claim\"\n",
    "- Loss_Ratio: Claims/Premiums (capped at 5.0)\n",
    "\n",
    "ML PREDICTIONS:\n",
    "- Predicted_Claim_Probability: Claim risk (0-1)\n",
    "- Predicted_Premium: Recommended premium ($)\n",
    "- Premium_Gap: Predicted - Current ($)\n",
    "- Is_Underpriced: Underpriced or Fair/Overpriced\n",
    "\n",
    "STATE SUMMARY: state_summary.csv ({len(state_summary)} states)\n",
    "------------------------------------------------------\n",
    "Aggregated metrics by state\n",
    "\n",
    "RISK SUMMARY: risk_summary.csv ({len(risk_summary)} categories)\n",
    "---------------------------------------------------\n",
    "Aggregated metrics by risk level\n",
    "\"\"\"\n",
    "\n",
    "with open('outputs/powerbi/DATA_DICTIONARY.txt', 'w') as f:\n",
    "    f.write(data_dictionary)\n",
    "\n",
    "print(\"âœ… Data dictionary: outputs/powerbi/DATA_DICTIONARY.txt\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Summary\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… POWERBI DATA PREPARATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Dataset Summary:\")\n",
    "print(f\"   Records:     {len(powerbi_data):,}\")\n",
    "print(f\"   Columns:     {powerbi_data.shape[1]}\")\n",
    "print(f\"   States:      {powerbi_data['state'].nunique()}\")\n",
    "print(f\"   Total Value: ${powerbi_data['property_value'].sum()/1e9:.2f}B\")\n",
    "\n",
    "print(f\"\\nğŸ“‚ Files ready for PowerBI:\")\n",
    "print(f\"   1. climate_risk_data.csv     ({len(powerbi_data):,} rows)\")\n",
    "print(f\"   2. state_summary.csv         ({len(state_summary)} states)\")\n",
    "print(f\"   3. risk_summary.csv          ({len(risk_summary)} categories)\")\n",
    "print(f\"   4. DATA_DICTIONARY.txt       (column guide)\")\n",
    "\n",
    "print(\"\\nğŸ¯ Next Steps:\")\n",
    "print(\"   1. Open PowerBI Desktop\")\n",
    "print(\"   2. Import climate_risk_data.csv\")\n",
    "print(\"   3. Follow dashboard creation guide\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad1719-f8c2-4aab-997f-a0da0d95cf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
